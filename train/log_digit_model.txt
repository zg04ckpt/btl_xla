python train_digits.py
2025-11-30 22:24:12.013244: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-30 22:24:15.152222: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
============================================================
CNN MODEL TRAINING - MNIST
============================================================
C:\Users\Long\scoop\apps\python\current\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-11-30 22:24:18.515547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

Starting training...
C:\Users\Long\scoop\apps\python\current\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 65s 133ms/step - accuracy: 0.7767 - loss: 0.7131 - val_accuracy: 0.6991 - val_loss: 0.9215 - learning_rate: 0.0010
Epoch 2/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 61s 129ms/step - accuracy: 0.9390 - loss: 0.2034 - val_accuracy: 0.9842 - val_loss: 0.0488 - learning_rate: 0.0010
Epoch 3/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 60s 127ms/step - accuracy: 0.9568 - loss: 0.1435 - val_accuracy: 0.9813 - val_loss: 0.0619 - learning_rate: 0.0010
Epoch 4/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 55s 117ms/step - accuracy: 0.9668 - loss: 0.1129 - val_accuracy: 0.9827 - val_loss: 0.0548 - learning_rate: 0.0010
Epoch 5/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 58s 124ms/step - accuracy: 0.9709 - loss: 0.0984 - val_accuracy: 0.9918 - val_loss: 0.0254 - learning_rate: 0.0010
Epoch 6/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 75s 109ms/step - accuracy: 0.9727 - loss: 0.0916 - val_accuracy: 0.9919 - val_loss: 0.0243 - learning_rate: 0.0010
Epoch 7/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9763 - loss: 0.0815 - val_accuracy: 0.9883 - val_loss: 0.0393 - learning_rate: 0.0010
Epoch 8/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 114ms/step - accuracy: 0.9778 - loss: 0.0751 - val_accuracy: 0.9899 - val_loss: 0.0332 - learning_rate: 0.0010
Epoch 9/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 57s 122ms/step - accuracy: 0.9792 - loss: 0.0698 - val_accuracy: 0.9894 - val_loss: 0.0359 - learning_rate: 0.0010
Epoch 10/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 57s 120ms/step - accuracy: 0.9838 - loss: 0.0579 - val_accuracy: 0.9930 - val_loss: 0.0196 - learning_rate: 5.0000e-04
Epoch 11/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 55s 118ms/step - accuracy: 0.9851 - loss: 0.0533 - val_accuracy: 0.9943 - val_loss: 0.0192 - learning_rate: 5.0000e-04
Epoch 12/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9849 - loss: 0.0532 - val_accuracy: 0.9928 - val_loss: 0.0208 - learning_rate: 5.0000e-04
Epoch 13/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9857 - loss: 0.0491 - val_accuracy: 0.9946 - val_loss: 0.0149 - learning_rate: 5.0000e-04
Epoch 14/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9857 - loss: 0.0474 - val_accuracy: 0.9954 - val_loss: 0.0158 - learning_rate: 5.0000e-04
Epoch 15/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9849 - loss: 0.0492 - val_accuracy: 0.9955 - val_loss: 0.0137 - learning_rate: 5.0000e-04
Epoch 16/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9864 - loss: 0.0469 - val_accuracy: 0.9940 - val_loss: 0.0182 - learning_rate: 5.0000e-04
Epoch 17/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9871 - loss: 0.0440 - val_accuracy: 0.9933 - val_loss: 0.0203 - learning_rate: 5.0000e-04
Epoch 18/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 116ms/step - accuracy: 0.9868 - loss: 0.0436 - val_accuracy: 0.9953 - val_loss: 0.0129 - learning_rate: 5.0000e-04
Epoch 19/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9881 - loss: 0.0420 - val_accuracy: 0.9951 - val_loss: 0.0156 - learning_rate: 5.0000e-04
Epoch 20/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9876 - loss: 0.0421 - val_accuracy: 0.9939 - val_loss: 0.0184 - learning_rate: 5.0000e-04
Epoch 21/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 114ms/step - accuracy: 0.9879 - loss: 0.0407 - val_accuracy: 0.9940 - val_loss: 0.0191 - learning_rate: 5.0000e-04
Epoch 22/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 114ms/step - accuracy: 0.9894 - loss: 0.0364 - val_accuracy: 0.9958 - val_loss: 0.0120 - learning_rate: 2.5000e-04
Epoch 23/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 114ms/step - accuracy: 0.9896 - loss: 0.0343 - val_accuracy: 0.9959 - val_loss: 0.0122 - learning_rate: 2.5000e-04
Epoch 24/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9899 - loss: 0.0346 - val_accuracy: 0.9957 - val_loss: 0.0127 - learning_rate: 2.5000e-04
Epoch 25/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 115ms/step - accuracy: 0.9900 - loss: 0.0336 - val_accuracy: 0.9960 - val_loss: 0.0131 - learning_rate: 2.5000e-04
Epoch 26/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 55s 118ms/step - accuracy: 0.9906 - loss: 0.0317 - val_accuracy: 0.9962 - val_loss: 0.0120 - learning_rate: 1.2500e-04
Epoch 27/30
469/469 ━━━━━━━━━━━━━━━━━━━━ 54s 116ms/step - accuracy: 0.9913 - loss: 0.0305 - val_accuracy: 0.9961 - val_loss: 0.0131 - learning_rate: 1.2500e-04

============================================================
Test Accuracy: 99.58%
============================================================
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
Model saved: mnist_cnn_model.h5